{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "f99de020b342f6398c2daa900581ba139c9d64acb9dee4fdd8018694687cc700"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import copy"
   ]
  },
  {
   "source": [
    "# Import Dataset and Overview"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df = pd.read_csv(\"bank_note_authentication.csv\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "source": [
    "print(df.shape)\n",
    "print(df.tail())\n",
    "df.describe()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1372, 5)\n      variance  skewness  curtosis  entropy  class\n1367   0.40614   1.34920   -1.4501 -0.55949      1\n1368  -1.38870  -4.87730    6.4774  0.34179      1\n1369  -3.75030 -13.45860   17.5932 -2.77710      1\n1370  -3.56370  -8.38270   12.3930 -1.28230      1\n1371  -2.54190  -0.65804    2.6842  1.19520      1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variance</th>\n      <th>skewness</th>\n      <th>curtosis</th>\n      <th>entropy</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1372.000000</td>\n      <td>1372.000000</td>\n      <td>1372.000000</td>\n      <td>1372.000000</td>\n      <td>1372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.433735</td>\n      <td>1.922353</td>\n      <td>1.397627</td>\n      <td>-1.191657</td>\n      <td>0.444606</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.842763</td>\n      <td>5.869047</td>\n      <td>4.310030</td>\n      <td>2.101013</td>\n      <td>0.497103</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-7.042100</td>\n      <td>-13.773100</td>\n      <td>-5.286100</td>\n      <td>-8.548200</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.773000</td>\n      <td>-1.708200</td>\n      <td>-1.574975</td>\n      <td>-2.413450</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.496180</td>\n      <td>2.319650</td>\n      <td>0.616630</td>\n      <td>-0.586650</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.821475</td>\n      <td>6.814625</td>\n      <td>3.179250</td>\n      <td>0.394810</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.824800</td>\n      <td>12.951600</td>\n      <td>17.927400</td>\n      <td>2.449500</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "# Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from pandas_profiling import ProfileReport"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "source": [
    "profile = ProfileReport (df, title=\"pandas_Profiling_Report\", explorative=True)\n",
    "\n",
    "profile.to_widgets()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset: 100%|██████████| 19/19 [00:13<00:00,  1.40it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b1ab0df80c640858459f63587a424ba"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "source": [
    "## Removing Duplicate Rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1348, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df1 = df[~(df.duplicated())]\n",
    "df1.shape"
   ]
  },
  {
   "source": [
    "## Select Independant and Dependant Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      variance  skewness  curtosis  entropy\n0      3.62160   8.66610   -2.8073 -0.44699\n1      4.54590   8.16740   -2.4586 -1.46210\n2      3.86600  -2.63830    1.9242  0.10645\n3      3.45660   9.52280   -4.0112 -3.59440\n4      0.32924  -4.45520    4.5718 -0.98880\n...        ...       ...       ...      ...\n1367   0.40614   1.34920   -1.4501 -0.55949\n1368  -1.38870  -4.87730    6.4774  0.34179\n1369  -3.75030 -13.45860   17.5932 -2.77710\n1370  -3.56370  -8.38270   12.3930 -1.28230\n1371  -2.54190  -0.65804    2.6842  1.19520\n\n[1348 rows x 4 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1367    1\n",
       "1368    1\n",
       "1369    1\n",
       "1370    1\n",
       "1371    1\n",
       "Name: class, Length: 1348, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X = df1.iloc[:,0:4]\r\n",
    "y = df1.iloc[:,4]\r\n",
    "print(X)\r\n",
    "y"
   ]
  },
  {
   "source": [
    "## Normalizing Independant Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_X = st.fit_transform(X)"
   ]
  },
  {
   "source": [
    "## Train Test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(st_X,y, test_size=0.2,random_state=7)"
   ]
  },
  {
   "source": [
    "# Model Building"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "source": [
    "lr = LogisticRegression()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\uf ruman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "lr.predict([[3,-4,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "source": [
    "## check accuracy_score,classification_report and confution_matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicte_y = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00       156\\n           1       1.00      1.00      1.00       114\\n\\n    accuracy                           1.00       270\\n   macro avg       1.00      1.00      1.00       270\\nweighted avg       1.00      1.00      1.00       270\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "classification_report(y_test,predicte_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "accuracy_score(y_test,predicte_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[156,   0],\n",
       "       [  0, 114]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicte_y)"
   ]
  },
  {
   "source": [
    "## save model in Pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_pickle.pkl\",'wb') as m:\n",
    "    pickle.dump(lr,m)"
   ]
  },
  {
   "source": [
    "# THANKS\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}